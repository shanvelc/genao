{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanvelc/genao/blob/main/Shan_M5_NB_MiniProject_1_Medical_Q%26A_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgLag1Euy3H"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A programme by IISc and TalentSprint\n",
        "### Mini-Project: Medical Q&A using GPT2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdtrlAhvIHY"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* perform data preprocessing, EDA and feature extraction on the Medical Q&A dataset\n",
        "* load a pre-trained tokenizer\n",
        "* finetune a GPT-2 language model for medical question-answering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description\n",
        "\n",
        "The dataset used in this project is the *Medical Question Answering Dataset* ([MedQuAD](https://github.com/abachaa/MedQuAD/tree/master)). It includes medical question-answer pairs along with additional information, such as the question type, the question *focus*, its UMLS(Unified Medical Language System) details like - Concept Unique Identifier(*CUI*) and Semantic *Type* and *Group*.\n",
        "\n",
        "To know more about this data's collection, and construction method, refer to this [paper](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4).\n",
        "\n",
        "The data is extracted and is in CSV format with below features:\n",
        "\n",
        "- **Focus**: the question focus\n",
        "- **CUI**: concept unique identifier\n",
        "- **SemanticType**\n",
        "- **SemanticGroup**\n",
        "- **Question**\n",
        "- **Answer**"
      ],
      "metadata": {
        "id": "2nmP8OaXuO--"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ZV5ryMP07f"
      },
      "source": [
        "## Part-A: Grading = 10 Points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pped-3NPaDV"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Healthcare professionals often have to refer to medical literature and documents while seeking answers to medical queries. Medical databases or search engines are powerful resources of upto date medical knowledge. However, the existing documentation is large and makes it difficult for professionals to retrieve answers quickly in a clinical setting. The problem with search engines and informative retrieval engines is that these systems return a list of documents rather than answers. Instead, healthcare professionals can use question answering systems to retrieve short sentences or paragraphs in response to medical queries. Such systems have the biggest advantage of generating answers and providing hints in a few seconds."
      ],
      "metadata": {
        "id": "dW4w8T3jEPhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement"
      ],
      "metadata": {
        "id": "YN15WtbfwPkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune gpt2 model on medical-question-answering-dataset for performing response generation for medical queries.\n",
        "\n",
        "Please refer to ***M6 Assignment-1 Fine-tune GPT2*** to get familiar with how to load pre-trained gpt2 tokenizer and model."
      ],
      "metadata": {
        "id": "R8_CoX7swR14"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RH8Ecq9sbYU"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U accelerate\n",
        "!pip -q install -U transformers\n",
        "!pip -q install torch"
      ],
      "metadata": {
        "id": "74vfKQ0RtRkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JfqnHAnMYfWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "!wget -q https://cdn.iisc.talentsprint.com/AIandMLOps/MiniProjects/Datasets/MedQuAD.csv\n",
        "!ls | grep \".csv\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "G0_3Qr2nI7B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3FkLI6wcaat"
      },
      "source": [
        "**Exercise 1: Read the MedQuAD.csv dataset**\n",
        "\n",
        "**Hint:** pd.read_csv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"MedQuAD.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "id": "m8Uwi8cYJ0Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "P-J6gSL_J9kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvddL7X69NiB"
      },
      "source": [
        "### Pre-processing and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2: Perform below operations on the dataset [0.5 Mark]**\n",
        "\n",
        "- Handle missing values\n",
        "- Remove duplicates from data considering `Question` and `Answer` columns"
      ],
      "metadata": {
        "id": "xgB7KCn88Vmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handle missing values**"
      ],
      "metadata": {
        "id": "TkabbxoGKFkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "H6mM7DM1KH_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "uNyjYvNu_48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Remove duplicates from data considering `Question` and `Answer` columns**"
      ],
      "metadata": {
        "id": "0KpssAWUBiok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicates\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YEv2TMQPs-Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EYg8zF7itkf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicates\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "5haFMucZtwiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA1d25HrzTGW"
      },
      "source": [
        "**Exercise 3: Display the category name, and the number of records belonging to top 100 categories of `Focus` column [1 Mark]**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "kRxuMduGSWYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 100 Focus categories names\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "_Xa8jp6AKVkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Training and Validation set"
      ],
      "metadata": {
        "id": "clJZkJLzwDWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4: Create training and validation set [2 Marks]**\n",
        "\n",
        "- Consider 4 samples per `Focus` category, for each top 100 categories, from the dataset (It will give 400 samples for training)\n",
        "\n",
        "- Consider 1 sample per `Focus` category (different from training set), for each top 100 categories, from the dataset (It will give 100 samples for validation)"
      ],
      "metadata": {
        "id": "JDQOWgthKgGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "CWoHsbibKtdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-process `Question` and `Answer` text\n",
        "\n",
        "**Exercise 5: Perform below tasks: [1.5 Marks]**\n",
        "\n",
        "- Combine `Question` and `Answer` for train and validation data as shown below:\n",
        "    - sequence = *'\\<question\\>' + question-text + '\\<answer\\>' + answer-text*\n",
        "\n",
        "- Join the combined text using '\\n' into a single string for training and validation separately\n",
        "\n",
        "- Save the training and validation strings as separate text files"
      ],
      "metadata": {
        "id": "YxjnEkqScZEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Combine Question and Answer for train and val data**"
      ],
      "metadata": {
        "id": "48ieeFrU0vmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "nxT84SYwONaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Join the combined text using '\\n' into a single string for training and validation separately**"
      ],
      "metadata": {
        "id": "Uzny8Cci1ZOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "vwKbaMAfPCM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Save the training and validation strings as text files**"
      ],
      "metadata": {
        "id": "GJZ9GHGSwNtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "pLQaAIhYMRvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6: Load pre-trained GPT2Tokenizer [0.5 Mark]**\n",
        "\n",
        "- Use checkpoint = \"gpt2\""
      ],
      "metadata": {
        "id": "Y1hlYtjjML1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "-qiMe9TAplyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 7: Tokenize train and validation data and form TextDataset objects [0.5 Mark]**\n",
        "\n",
        "- Use the loaded pre-trained tokenizer\n",
        "- Use training and validation data saved in text files"
      ],
      "metadata": {
        "id": "InX4FOvgP0mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "crjMEbLfVOpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 8: Create a DataCollator object [0.5 Mark]**"
      ],
      "metadata": {
        "id": "QjN3cYyMkV74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Z_XWmIF3cmhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9: Load pre-trained GPT2LMHeadModel [0.5 Mark]**"
      ],
      "metadata": {
        "id": "uophCXjYq9MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "HxQWgssCqy7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 10: Fine-tune GPT2 Model [1 Mark]**\n",
        "\n",
        "- Specify training arguments and create a TrainingArguments object (Use 30 epochs)\n",
        "\n",
        "- Train a GPT-2 model using the provided training arguments\n",
        "\n",
        "- Save the resulting trained model and tokenizer to a specified output directory"
      ],
      "metadata": {
        "id": "LdcpMx9QOPnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the training arguments\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "UPZiEvn2cuPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Save the model\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Save the tokenizer\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "drF9-oZwQLYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 11: Test Model with user input prompts [1 Mark]**\n",
        "\n",
        "- Create `generate_response()` function that takes a trained *model*, *tokenizer*, and a *prompt* string as input and generates a response using the GPT-2 model\n",
        "\n",
        "- Test it with some user input prompts"
      ],
      "metadata": {
        "id": "4izo_-go8cDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "qeTKPArfgDJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "pJJ3bzD9fsJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Response from model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "UCkZjYC_ht7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with given prompt 1\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "DlVNC0LliaMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with given prompt 2\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "WWOTby9IiyQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 12: Compare the performance of a *GPT2 model* with the *GPT2 model fine-tuned* on MedQuAD data [1 Mark]**\n",
        "\n",
        "- Load another pre-trained GPT2LMHeadModel and do not fine-tune it\n",
        "\n",
        "- To generate response using the untuned model, pass it as a parameter to `generate_response()` function\n",
        "\n",
        "- Test both models (fine-tuned and untuned) with below user input prompts:\n",
        "\n",
        "    - \"What precautions to take for a healthy life?\"\n",
        "    - \"What to do after being diagnosed with cancer?\"\n",
        "    - \"What to do when feeling sick?\""
      ],
      "metadata": {
        "id": "NO_AdtZc8ThO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained GPT2 model, do not finetune it with MedQuAD data\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "u7Inq43Q524A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with finetuned model: prompt 1\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "wb58jO6b4gC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with untuned model: prompt 1\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "q3rN6ETD46PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with finetuned model: prompt 2\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Pl0ChnZn6XVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with untuned model: prompt 2\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "gG4lVy3F6u2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with finetuned model: prompt 3\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "yqu9MAci7dvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with untuned model: prompt 3\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "jdj0En4o61Zj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}